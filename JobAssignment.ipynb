{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JobAssignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MasoudMoeini/Neural-Networks/blob/master/JobAssignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCW5U_F4yd1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shfTp_Lgyd1U",
        "colab_type": "code",
        "colab": {},
        "outputId": "623929fa-0718-42cc-a882-347a68a91334"
      },
      "source": [
        "#Three steps\n",
        "#1.Data pre-processing and quick analysis\n",
        "#2.Building ANN\n",
        "#3.Making Predictions So let's get started!\n",
        "df=pd.read_csv('data CSV test file.csv',delimiter=\",\")\n",
        "df.head()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>f0</th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "      <th>f7</th>\n",
              "      <th>...</th>\n",
              "      <th>f327</th>\n",
              "      <th>f328</th>\n",
              "      <th>f329</th>\n",
              "      <th>f330</th>\n",
              "      <th>f331</th>\n",
              "      <th>f332</th>\n",
              "      <th>f333</th>\n",
              "      <th>f334</th>\n",
              "      <th>f335</th>\n",
              "      <th>f336</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.003207</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0.453137</td>\n",
              "      <td>0.598487</td>\n",
              "      <td>0.493430</td>\n",
              "      <td>0.026024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.001602</td>\n",
              "      <td>0.006970</td>\n",
              "      <td>8.439819</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0.324856</td>\n",
              "      <td>0.778154</td>\n",
              "      <td>0.580938</td>\n",
              "      <td>0.104651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.004286</td>\n",
              "      <td>0.019157</td>\n",
              "      <td>3.864468</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0.278645</td>\n",
              "      <td>0.620438</td>\n",
              "      <td>0.405717</td>\n",
              "      <td>0.060614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.041829</td>\n",
              "      <td>0.123117</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0.004389</td>\n",
              "      <td>0.921269</td>\n",
              "      <td>0.792154</td>\n",
              "      <td>0.160846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.006576</td>\n",
              "      <td>0.015534</td>\n",
              "      <td>0.968838</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0.601719</td>\n",
              "      <td>0.810780</td>\n",
              "      <td>0.712691</td>\n",
              "      <td>0.031670</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 339 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  label        f0        f1           f2      f3      f4      f5  \\\n",
              "0           0      0  0.003207  0.000000  1000.000000  1000.0  1000.0  1000.0   \n",
              "1           1      0  0.001602  0.006970     8.439819  1000.0  1000.0  1000.0   \n",
              "2           2      0  0.004286  0.019157     3.864468  1000.0  1000.0  1000.0   \n",
              "3           3      0  0.041829  0.123117  1000.000000  1000.0  1000.0  1000.0   \n",
              "4           4      0  0.006576  0.015534     0.968838  1000.0  1000.0  1000.0   \n",
              "\n",
              "       f6      f7  ...    f327    f328    f329    f330    f331    f332  \\\n",
              "0  1000.0  1000.0  ...  1000.0  1000.0  1000.0  1000.0  1000.0  1000.0   \n",
              "1  1000.0  1000.0  ...  1000.0  1000.0  1000.0  1000.0  1000.0  1000.0   \n",
              "2  1000.0  1000.0  ...  1000.0  1000.0  1000.0  1000.0  1000.0  1000.0   \n",
              "3  1000.0  1000.0  ...  1000.0  1000.0  1000.0  1000.0  1000.0  1000.0   \n",
              "4  1000.0  1000.0  ...  1000.0  1000.0  1000.0  1000.0  1000.0  1000.0   \n",
              "\n",
              "       f333      f334      f335      f336  \n",
              "0  0.453137  0.598487  0.493430  0.026024  \n",
              "1  0.324856  0.778154  0.580938  0.104651  \n",
              "2  0.278645  0.620438  0.405717  0.060614  \n",
              "3  0.004389  0.921269  0.792154  0.160846  \n",
              "4  0.601719  0.810780  0.712691  0.031670  \n",
              "\n",
              "[5 rows x 339 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvWhtiXLyd1Y",
        "colab_type": "code",
        "colab": {},
        "outputId": "20494070-1685-42bd-ddac-63483c0972e3"
      },
      "source": [
        "#check number of rows and columns in dataset\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1261, 339)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8ygfkJSyd1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.drop(columns=['label'])\n",
        "X=X.iloc[:,1:338].values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdBknYf1yd1e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df['label'].values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c84YqwG5yd1h",
        "colab_type": "code",
        "colab": {},
        "outputId": "5074eb80-3289-42e6-dd78-9e4cb0d2ca55"
      },
      "source": [
        "#Split the dataset into train and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "#split dataset into train and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "#â€ŠFeature Scaling\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "np.shape(X_train)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1008, 337)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU0euuyZyd1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "classifier = Sequential() # Initialising the ANN\n",
        "\n",
        "classifier.add(Dense(units =337 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 337))\n",
        "classifier.add(Dense(units = 170, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "classifier.add(Dense(units = 85, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "classifier.add(Dense(units = 40, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "classifier.add(Dense(units = 20, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "classifier.add(Dense(units = 10, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "classifier.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzRUGmX5yd1n",
        "colab_type": "code",
        "colab": {},
        "outputId": "ea979242-5ef0-41f2-a45f-42f152ef32a2"
      },
      "source": [
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "classifier.fit(X_train, y_train, batch_size = 20, epochs = 100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1008/1008 [==============================] - 1s 1ms/step - loss: 0.6741 - acc: 0.8740\n",
            "Epoch 2/100\n",
            "1008/1008 [==============================] - 0s 267us/step - loss: 0.2456 - acc: 0.8740\n",
            "Epoch 3/100\n",
            "1008/1008 [==============================] - 0s 239us/step - loss: 0.1889 - acc: 0.8740\n",
            "Epoch 4/100\n",
            "1008/1008 [==============================] - 0s 245us/step - loss: 0.1703 - acc: 0.8740\n",
            "Epoch 5/100\n",
            "1008/1008 [==============================] - 0s 250us/step - loss: 0.1523 - acc: 0.8740\n",
            "Epoch 6/100\n",
            "1008/1008 [==============================] - 0s 245us/step - loss: 0.1440 - acc: 0.8740\n",
            "Epoch 7/100\n",
            "1008/1008 [==============================] - 0s 250us/step - loss: 0.1371 - acc: 0.8819\n",
            "Epoch 8/100\n",
            "1008/1008 [==============================] - 0s 245us/step - loss: 0.1354 - acc: 0.9573\n",
            "Epoch 9/100\n",
            "1008/1008 [==============================] - 0s 247us/step - loss: 0.1277 - acc: 0.9653\n",
            "Epoch 10/100\n",
            "1008/1008 [==============================] - 0s 250us/step - loss: 0.1200 - acc: 0.9613\n",
            "Epoch 11/100\n",
            "1008/1008 [==============================] - 0s 245us/step - loss: 0.1245 - acc: 0.9673\n",
            "Epoch 12/100\n",
            "1008/1008 [==============================] - 0s 247us/step - loss: 0.1185 - acc: 0.9692\n",
            "Epoch 13/100\n",
            "1008/1008 [==============================] - 0s 259us/step - loss: 0.1128 - acc: 0.9673\n",
            "Epoch 14/100\n",
            "1008/1008 [==============================] - 0s 264us/step - loss: 0.1081 - acc: 0.9702\n",
            "Epoch 15/100\n",
            "1008/1008 [==============================] - 0s 251us/step - loss: 0.1028 - acc: 0.9702\n",
            "Epoch 16/100\n",
            "1008/1008 [==============================] - 0s 265us/step - loss: 0.1049 - acc: 0.9633\n",
            "Epoch 17/100\n",
            "1008/1008 [==============================] - 0s 274us/step - loss: 0.1042 - acc: 0.9663\n",
            "Epoch 18/100\n",
            "1008/1008 [==============================] - 0s 248us/step - loss: 0.1031 - acc: 0.9613\n",
            "Epoch 19/100\n",
            "1008/1008 [==============================] - 0s 279us/step - loss: 0.0999 - acc: 0.9673\n",
            "Epoch 20/100\n",
            "1008/1008 [==============================] - 0s 260us/step - loss: 0.0965 - acc: 0.9663\n",
            "Epoch 21/100\n",
            "1008/1008 [==============================] - 0s 243us/step - loss: 0.0991 - acc: 0.9683\n",
            "Epoch 22/100\n",
            "1008/1008 [==============================] - 0s 257us/step - loss: 0.0980 - acc: 0.9663\n",
            "Epoch 23/100\n",
            "1008/1008 [==============================] - 0s 260us/step - loss: 0.1013 - acc: 0.9633\n",
            "Epoch 24/100\n",
            "1008/1008 [==============================] - 0s 281us/step - loss: 0.0857 - acc: 0.9752\n",
            "Epoch 25/100\n",
            "1008/1008 [==============================] - 0s 245us/step - loss: 0.0733 - acc: 0.9782\n",
            "Epoch 26/100\n",
            "1008/1008 [==============================] - 0s 250us/step - loss: 0.0768 - acc: 0.9742\n",
            "Epoch 27/100\n",
            "1008/1008 [==============================] - 0s 244us/step - loss: 0.0743 - acc: 0.9762\n",
            "Epoch 28/100\n",
            "1008/1008 [==============================] - 0s 277us/step - loss: 0.0687 - acc: 0.9772\n",
            "Epoch 29/100\n",
            "1008/1008 [==============================] - 0s 271us/step - loss: 0.0690 - acc: 0.9772\n",
            "Epoch 30/100\n",
            "1008/1008 [==============================] - 0s 251us/step - loss: 0.0760 - acc: 0.9772\n",
            "Epoch 31/100\n",
            "1008/1008 [==============================] - 0s 239us/step - loss: 0.0689 - acc: 0.9762\n",
            "Epoch 32/100\n",
            "1008/1008 [==============================] - 0s 265us/step - loss: 0.0755 - acc: 0.9732\n",
            "Epoch 33/100\n",
            "1008/1008 [==============================] - 0s 248us/step - loss: 0.0787 - acc: 0.9732\n",
            "Epoch 34/100\n",
            "1008/1008 [==============================] - 0s 267us/step - loss: 0.0736 - acc: 0.9742\n",
            "Epoch 35/100\n",
            "1008/1008 [==============================] - 0s 267us/step - loss: 0.0876 - acc: 0.9692\n",
            "Epoch 36/100\n",
            "1008/1008 [==============================] - 0s 249us/step - loss: 0.0771 - acc: 0.9692\n",
            "Epoch 37/100\n",
            "1008/1008 [==============================] - 0s 248us/step - loss: 0.0716 - acc: 0.9722\n",
            "Epoch 38/100\n",
            "1008/1008 [==============================] - 0s 252us/step - loss: 0.0648 - acc: 0.9752\n",
            "Epoch 39/100\n",
            "1008/1008 [==============================] - 0s 260us/step - loss: 0.0715 - acc: 0.9762\n",
            "Epoch 40/100\n",
            "1008/1008 [==============================] - 0s 236us/step - loss: 0.0575 - acc: 0.9782\n",
            "Epoch 41/100\n",
            "1008/1008 [==============================] - 0s 263us/step - loss: 0.0580 - acc: 0.9762\n",
            "Epoch 42/100\n",
            "1008/1008 [==============================] - 0s 253us/step - loss: 0.0575 - acc: 0.9782\n",
            "Epoch 43/100\n",
            "1008/1008 [==============================] - 0s 252us/step - loss: 0.0478 - acc: 0.9821\n",
            "Epoch 44/100\n",
            "1008/1008 [==============================] - 0s 401us/step - loss: 0.0465 - acc: 0.9821\n",
            "Epoch 45/100\n",
            "1008/1008 [==============================] - 0s 301us/step - loss: 0.0479 - acc: 0.9802\n",
            "Epoch 46/100\n",
            "1008/1008 [==============================] - 0s 262us/step - loss: 0.0444 - acc: 0.9802\n",
            "Epoch 47/100\n",
            "1008/1008 [==============================] - 0s 259us/step - loss: 0.0415 - acc: 0.9821\n",
            "Epoch 48/100\n",
            "1008/1008 [==============================] - 0s 252us/step - loss: 0.0379 - acc: 0.9792\n",
            "Epoch 49/100\n",
            "1008/1008 [==============================] - 0s 250us/step - loss: 0.0383 - acc: 0.9821\n",
            "Epoch 50/100\n",
            "1008/1008 [==============================] - 0s 254us/step - loss: 0.0489 - acc: 0.9821\n",
            "Epoch 51/100\n",
            "1008/1008 [==============================] - 0s 258us/step - loss: 0.0841 - acc: 0.9692\n",
            "Epoch 52/100\n",
            "1008/1008 [==============================] - 0s 247us/step - loss: 0.0852 - acc: 0.9702\n",
            "Epoch 53/100\n",
            "1008/1008 [==============================] - 0s 260us/step - loss: 0.0689 - acc: 0.9683\n",
            "Epoch 54/100\n",
            "1008/1008 [==============================] - 0s 246us/step - loss: 0.0597 - acc: 0.9742\n",
            "Epoch 55/100\n",
            "1008/1008 [==============================] - 0s 241us/step - loss: 0.0418 - acc: 0.9802\n",
            "Epoch 56/100\n",
            "1008/1008 [==============================] - 0s 240us/step - loss: 0.0381 - acc: 0.9812\n",
            "Epoch 57/100\n",
            "1008/1008 [==============================] - 0s 249us/step - loss: 0.0367 - acc: 0.9831\n",
            "Epoch 58/100\n",
            "1008/1008 [==============================] - 0s 303us/step - loss: 0.0337 - acc: 0.9831\n",
            "Epoch 59/100\n",
            "1008/1008 [==============================] - 0s 267us/step - loss: 0.0338 - acc: 0.9841\n",
            "Epoch 60/100\n",
            "1008/1008 [==============================] - 0s 246us/step - loss: 0.0322 - acc: 0.9841\n",
            "Epoch 61/100\n",
            "1008/1008 [==============================] - 0s 257us/step - loss: 0.0317 - acc: 0.9871\n",
            "Epoch 62/100\n",
            "1008/1008 [==============================] - 0s 258us/step - loss: 0.0320 - acc: 0.9871\n",
            "Epoch 63/100\n",
            "1008/1008 [==============================] - 0s 243us/step - loss: 0.0317 - acc: 0.9831\n",
            "Epoch 64/100\n",
            "1008/1008 [==============================] - 0s 269us/step - loss: 0.0270 - acc: 0.9871\n",
            "Epoch 65/100\n",
            "1008/1008 [==============================] - 0s 244us/step - loss: 0.0344 - acc: 0.9802\n",
            "Epoch 66/100\n",
            "1008/1008 [==============================] - 0s 281us/step - loss: 0.0318 - acc: 0.9861\n",
            "Epoch 67/100\n",
            "1008/1008 [==============================] - 0s 265us/step - loss: 0.0333 - acc: 0.9802\n",
            "Epoch 68/100\n",
            "1008/1008 [==============================] - 0s 240us/step - loss: 0.0320 - acc: 0.9841\n",
            "Epoch 69/100\n",
            "1008/1008 [==============================] - 0s 281us/step - loss: 0.0300 - acc: 0.9851\n",
            "Epoch 70/100\n",
            "1008/1008 [==============================] - 0s 258us/step - loss: 0.0293 - acc: 0.9831\n",
            "Epoch 71/100\n",
            "1008/1008 [==============================] - 0s 249us/step - loss: 0.0285 - acc: 0.9861\n",
            "Epoch 72/100\n",
            "1008/1008 [==============================] - 0s 279us/step - loss: 0.0308 - acc: 0.9841\n",
            "Epoch 73/100\n",
            "1008/1008 [==============================] - 0s 251us/step - loss: 0.0284 - acc: 0.9851\n",
            "Epoch 74/100\n",
            "1008/1008 [==============================] - 0s 248us/step - loss: 0.0408 - acc: 0.9821\n",
            "Epoch 75/100\n",
            "1008/1008 [==============================] - 0s 250us/step - loss: 0.0566 - acc: 0.9792\n",
            "Epoch 76/100\n",
            "1008/1008 [==============================] - 0s 279us/step - loss: 0.0381 - acc: 0.9792\n",
            "Epoch 77/100\n",
            "1008/1008 [==============================] - 0s 262us/step - loss: 0.0315 - acc: 0.9861\n",
            "Epoch 78/100\n",
            "1008/1008 [==============================] - 0s 254us/step - loss: 0.0301 - acc: 0.9841\n",
            "Epoch 79/100\n",
            "1008/1008 [==============================] - 0s 265us/step - loss: 0.0304 - acc: 0.9861\n",
            "Epoch 80/100\n",
            "1008/1008 [==============================] - 0s 247us/step - loss: 0.0295 - acc: 0.9851\n",
            "Epoch 81/100\n",
            "1008/1008 [==============================] - 0s 262us/step - loss: 0.0279 - acc: 0.9871\n",
            "Epoch 82/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1008/1008 [==============================] - 0s 252us/step - loss: 0.0296 - acc: 0.9861\n",
            "Epoch 83/100\n",
            "1008/1008 [==============================] - 0s 237us/step - loss: 0.0274 - acc: 0.9861\n",
            "Epoch 84/100\n",
            "1008/1008 [==============================] - 0s 263us/step - loss: 0.0280 - acc: 0.9851\n",
            "Epoch 85/100\n",
            "1008/1008 [==============================] - 0s 243us/step - loss: 0.0298 - acc: 0.9861\n",
            "Epoch 86/100\n",
            "1008/1008 [==============================] - 0s 265us/step - loss: 0.0280 - acc: 0.9871\n",
            "Epoch 87/100\n",
            "1008/1008 [==============================] - 0s 248us/step - loss: 0.0295 - acc: 0.9891\n",
            "Epoch 88/100\n",
            "1008/1008 [==============================] - 0s 245us/step - loss: 0.0320 - acc: 0.9871\n",
            "Epoch 89/100\n",
            "1008/1008 [==============================] - 0s 267us/step - loss: 0.0290 - acc: 0.9851\n",
            "Epoch 90/100\n",
            "1008/1008 [==============================] - 0s 241us/step - loss: 0.0291 - acc: 0.9841\n",
            "Epoch 91/100\n",
            "1008/1008 [==============================] - 0s 263us/step - loss: 0.0252 - acc: 0.9881\n",
            "Epoch 92/100\n",
            "1008/1008 [==============================] - 0s 233us/step - loss: 0.0919 - acc: 0.9841\n",
            "Epoch 93/100\n",
            "1008/1008 [==============================] - 0s 274us/step - loss: 0.2526 - acc: 0.9554\n",
            "Epoch 94/100\n",
            "1008/1008 [==============================] - 0s 241us/step - loss: 0.1123 - acc: 0.9633\n",
            "Epoch 95/100\n",
            "1008/1008 [==============================] - 0s 263us/step - loss: 0.0672 - acc: 0.9742\n",
            "Epoch 96/100\n",
            "1008/1008 [==============================] - 0s 244us/step - loss: 0.0477 - acc: 0.9821\n",
            "Epoch 97/100\n",
            "1008/1008 [==============================] - 0s 246us/step - loss: 0.0341 - acc: 0.9821\n",
            "Epoch 98/100\n",
            "1008/1008 [==============================] - 0s 272us/step - loss: 0.0320 - acc: 0.9831\n",
            "Epoch 99/100\n",
            "1008/1008 [==============================] - 0s 246us/step - loss: 0.0363 - acc: 0.9861\n",
            "Epoch 100/100\n",
            "1008/1008 [==============================] - 0s 252us/step - loss: 0.0408 - acc: 0.9841\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1b32412e748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utBR_NJZyd1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "classifier.save('job_assignment_model.h5') #Save trained ANN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUlmD8Ynyd1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Making Predictions\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = [ 1 if y>=0.5 else 0 for y in y_pred ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgnR7Zy0yd1w",
        "colab_type": "code",
        "colab": {},
        "outputId": "307ef64a-4d9d-4d01-d914-d1e26d21951b"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "accuracy = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1])\n",
        "print(\"Accuracy: \"+ str(accuracy*100)+\"%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[204  13]\n",
            " [ 17  19]]\n",
            "Accuracy: 88.14229249011858%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ab7xOYiyd13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}